name: üöÄ Advanced Deployment Strategies

on:
  workflow_dispatch:
    inputs:
      strategy:
        description: 'Deployment Strategy'
        required: true
        default: 'canary'
        type: choice
        options:
        - canary
        - blue-green
        - ab-testing
        - rolling-update
        - shadow-traffic
      service:
        description: 'Target Service'
        required: true
        default: 'order-service'
        type: choice
        options:
        - order-service
        - payment-service
        - user-service
        - notification-service
      new_version:
        description: 'New Version Tag'
        required: true
        default: 'v2.0.0'
      traffic_percentage:
        description: 'Traffic Percentage for new version (1-100)'
        required: false
        default: '10'
      auto_rollback:
        description: 'Enable automatic rollback'
        required: false
        default: true
        type: boolean
      success_threshold:
        description: 'Success rate threshold for rollback (0.0-1.0)'
        required: false
        default: '0.95'
      latency_threshold:
        description: 'Latency threshold in ms for rollback'
        required: false
        default: '1000'

env:
  NAMESPACE: ecommerce-demo
  DOMAIN: ecommerce-demo.aks-labs.com
  CLUSTER_NAME: aks-labs
  RESOURCE_GROUP: rg-aks-labs

permissions:
  id-token: write
  contents: read

jobs:
  canary-deployment:
    if: github.event.inputs.strategy == 'canary'
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: üîÑ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üîê Azure Login via OIDC
      uses: azure/login@v1
      with:
        client-id: ${{ secrets.AZURE_CLIENT_ID }}
        tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        
    - name: ‚öôÔ∏è Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
        
    - name: üîó Get AKS Credentials
      run: |
        az aks get-credentials \
          --resource-group ${{ env.RESOURCE_GROUP }} \
          --name ${{ env.CLUSTER_NAME }} \
          --overwrite-existing
          
    - name: üê§ Deploy Canary Version
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        TRAFFIC_PERCENT="${{ github.event.inputs.traffic_percentage }}"
        
        echo "üöÄ Deploying canary version $NEW_VERSION of $SERVICE with $TRAFFIC_PERCENT% traffic"
        
        # Create canary deployment
        kubectl get deployment $SERVICE -n ${{ env.NAMESPACE }} -o yaml > /tmp/original-deployment.yaml
        
        # Patch deployment with new version
        kubectl patch deployment $SERVICE -n ${{ env.NAMESPACE }} --type='merge' -p="
        {
          \"metadata\": {
            \"labels\": {
              \"deployment-strategy\": \"canary\",
              \"canary-version\": \"$NEW_VERSION\"
            }
          },
          \"spec\": {
            \"selector\": {
              \"matchLabels\": {
                \"app\": \"$SERVICE\",
                \"version\": \"canary\"
              }
            },
            \"template\": {
              \"metadata\": {
                \"labels\": {
                  \"app\": \"$SERVICE\",
                  \"version\": \"canary\",
                  \"deployment-version\": \"$NEW_VERSION\"
                }
              },
              \"spec\": {
                \"containers\": [
                  {
                    \"name\": \"$SERVICE\",
                    \"image\": \"hashicorp/http-echo:latest\",
                    \"args\": [
                      \"-text={\\\"service\\\":\\\"$SERVICE\\\",\\\"version\\\":\\\"$NEW_VERSION\\\",\\\"status\\\":\\\"healthy\\\",\\\"timestamp\\\":\\\"$(date -Iseconds)\\\",\\\"canary\\\":true}\",
                      \"-listen=:8080\"
                    ]
                  }
                ]
              }
            }
          }
        }"
        
        # Create DestinationRule with subsets
        cat << EOF | kubectl apply -f -
        apiVersion: networking.istio.io/v1beta1
        kind: DestinationRule
        metadata:
          name: ${SERVICE}-canary-dr
          namespace: ${{ env.NAMESPACE }}
        spec:
          host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
          trafficPolicy:
            connectionPool:
              tcp:
                maxConnections: 50
              http:
                http1MaxPendingRequests: 10
                maxRequestsPerConnection: 2
            outlierDetection:
              consecutiveGatewayErrors: 3
              consecutive5xxErrors: 3
              interval: 30s
              baseEjectionTime: 30s
              maxEjectionPercent: 50
          subsets:
          - name: stable
            labels:
              version: v1
          - name: canary
            labels:
              version: canary
        EOF
        
        # Create VirtualService with traffic splitting
        STABLE_PERCENT=$((100 - TRAFFIC_PERCENT))
        cat << EOF | kubectl apply -f -
        apiVersion: networking.istio.io/v1beta1
        kind: VirtualService
        metadata:
          name: ${SERVICE}-canary-vs
          namespace: ${{ env.NAMESPACE }}
        spec:
          hosts:
          - ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
          http:
          - match:
            - headers:
                canary:
                  exact: "true"
            route:
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: canary
              weight: 100
          - route:
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: stable
              weight: $STABLE_PERCENT
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: canary
              weight: $TRAFFIC_PERCENT
        EOF
        
        echo "‚úÖ Canary deployment configured with $TRAFFIC_PERCENT% traffic"
        
    - name: üìä Monitor Canary Metrics
      id: monitor
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        SUCCESS_THRESHOLD="${{ github.event.inputs.success_threshold }}"
        LATENCY_THRESHOLD="${{ github.event.inputs.latency_threshold }}"
        
        echo "üìä Monitoring canary deployment for 5 minutes..."
        
        MONITORING_DURATION=300  # 5 minutes
        CHECK_INTERVAL=30        # 30 seconds
        CHECKS=$((MONITORING_DURATION / CHECK_INTERVAL))
        
        ROLLBACK_NEEDED=false
        
        for i in $(seq 1 $CHECKS); do
          echo "üîç Monitoring check $i/$CHECKS..."
          
          # Simulate metrics collection (in real scenario, query Prometheus)
          ERROR_RATE=$(echo "scale=3; $RANDOM % 1000 / 10000" | bc -l)
          LATENCY=$(echo "$RANDOM % 200 + 100" | bc)
          SUCCESS_RATE=$(echo "scale=3; 1 - $ERROR_RATE" | bc -l)
          
          echo "üìà Canary Metrics:"
          echo "  Success Rate: $SUCCESS_RATE"
          echo "  Error Rate: $ERROR_RATE"
          echo "  Latency P95: ${LATENCY}ms"
          
          # Check thresholds
          if (( $(echo "$SUCCESS_RATE < $SUCCESS_THRESHOLD" | bc -l) )); then
            echo "‚ùå Success rate ($SUCCESS_RATE) below threshold ($SUCCESS_THRESHOLD)"
            ROLLBACK_NEEDED=true
            break
          fi
          
          if (( $(echo "$LATENCY > $LATENCY_THRESHOLD" | bc -l) )); then
            echo "‚ùå Latency (${LATENCY}ms) above threshold (${LATENCY_THRESHOLD}ms)"
            ROLLBACK_NEEDED=true
            break
          fi
          
          echo "‚úÖ Metrics within acceptable range"
          sleep $CHECK_INTERVAL
        done
        
        echo "rollback_needed=$ROLLBACK_NEEDED" >> $GITHUB_OUTPUT
        
    - name: üîÑ Automatic Rollback
      if: steps.monitor.outputs.rollback_needed == 'true' && github.event.inputs.auto_rollback == 'true'
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        
        echo "üö® Initiating automatic rollback for $SERVICE"
        
        # Restore original deployment
        kubectl apply -f /tmp/original-deployment.yaml
        
        # Remove canary configurations
        kubectl delete virtualservice ${SERVICE}-canary-vs -n ${{ env.NAMESPACE }} --ignore-not-found=true
        kubectl delete destinationrule ${SERVICE}-canary-dr -n ${{ env.NAMESPACE }} --ignore-not-found=true
        
        # Wait for rollback to complete
        kubectl rollout status deployment/$SERVICE -n ${{ env.NAMESPACE }} --timeout=300s
        
        echo "‚úÖ Automatic rollback completed"
        exit 1
        
    - name: üéØ Promote Canary
      if: steps.monitor.outputs.rollback_needed == 'false'
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        
        echo "üéâ Promoting canary to 100% traffic"
        
        # Update VirtualService to route 100% to canary
        cat << EOF | kubectl apply -f -
        apiVersion: networking.istio.io/v1beta1
        kind: VirtualService
        metadata:
          name: ${SERVICE}-canary-vs
          namespace: ${{ env.NAMESPACE }}
        spec:
          hosts:
          - ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
          http:
          - route:
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: canary
              weight: 100
        EOF
        
        # Wait for traffic to stabilize
        sleep 60
        
        # Update stable deployment to new version
        kubectl patch deployment $SERVICE -n ${{ env.NAMESPACE }} --type='merge' -p="
        {
          \"spec\": {
            \"selector\": {
              \"matchLabels\": {
                \"app\": \"$SERVICE\",
                \"version\": \"v1\"
              }
            },
            \"template\": {
              \"metadata\": {
                \"labels\": {
                  \"app\": \"$SERVICE\",
                  \"version\": \"v1\",
                  \"deployment-version\": \"$NEW_VERSION\"
                }
              }
            }
          }
        }"
        
        # Clean up canary resources
        kubectl delete virtualservice ${SERVICE}-canary-vs -n ${{ env.NAMESPACE }}
        kubectl delete destinationrule ${SERVICE}-canary-dr -n ${{ env.NAMESPACE }}
        
        echo "‚úÖ Canary promotion completed successfully"

  blue-green-deployment:
    if: github.event.inputs.strategy == 'blue-green'
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: üîÑ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üîê Azure Login via OIDC
      uses: azure/login@v1
      with:
        client-id: ${{ secrets.AZURE_CLIENT_ID }}
        tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        
    - name: ‚öôÔ∏è Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
        
    - name: üîó Get AKS Credentials
      run: |
        az aks get-credentials \
          --resource-group ${{ env.RESOURCE_GROUP }} \
          --name ${{ env.CLUSTER_NAME }} \
          --overwrite-existing
          
    - name: üíö Deploy Green Environment
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        
        echo "üü¢ Deploying GREEN environment for $SERVICE version $NEW_VERSION"
        
        # Create green deployment
        kubectl get deployment $SERVICE -n ${{ env.NAMESPACE }} -o yaml | \
        sed "s/name: $SERVICE/name: ${SERVICE}-green/" | \
        sed "s/app: $SERVICE/app: ${SERVICE}-green/" | \
        sed "s/version: v1/version: green/" | \
        sed "s/deployment-version.*/deployment-version: $NEW_VERSION/" | \
        kubectl apply -f -
        
        # Wait for green deployment to be ready
        kubectl wait --for=condition=available deployment/${SERVICE}-green -n ${{ env.NAMESPACE }} --timeout=300s
        
        # Create green service
        kubectl get service $SERVICE -n ${{ env.NAMESPACE }} -o yaml | \
        sed "s/name: $SERVICE/name: ${SERVICE}-green/" | \
        sed "s/app: $SERVICE/app: ${SERVICE}-green/" | \
        kubectl apply -f -
        
        echo "‚úÖ Green environment deployed and ready"
        
    - name: üß™ Test Green Environment
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        
        echo "üß™ Testing GREEN environment..."
        
        # Run health checks against green service
        for i in {1..10}; do
          echo "Health check $i/10..."
          
          # Test green service directly
          kubectl run test-pod-$i --image=curlimages/curl --rm -i --restart=Never -n ${{ env.NAMESPACE }} -- \
            curl -f -s http://${SERVICE}-green.${{ env.NAMESPACE }}.svc.cluster.local:8080/ || {
            echo "‚ùå Health check failed"
            exit 1
          }
          
          sleep 5
        done
        
        echo "‚úÖ Green environment passed all health checks"
        
    - name: üîÑ Switch Traffic to Green
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        
        echo "üîÑ Switching traffic from BLUE to GREEN..."
        
        # Update service selector to point to green deployment
        kubectl patch service $SERVICE -n ${{ env.NAMESPACE }} --type='merge' -p="
        {
          \"spec\": {
            \"selector\": {
              \"app\": \"${SERVICE}-green\"
            }
          }
        }"
        
        # Update VirtualService to route to green
        cat << EOF | kubectl apply -f -
        apiVersion: networking.istio.io/v1beta1
        kind: VirtualService
        metadata:
          name: ${SERVICE}-bluegreen-vs
          namespace: ${{ env.NAMESPACE }}
        spec:
          hosts:
          - ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
          http:
          - route:
            - destination:
                host: ${SERVICE}-green.${{ env.NAMESPACE }}.svc.cluster.local
              weight: 100
        EOF
        
        echo "‚úÖ Traffic switched to GREEN environment"
        
    - name: üìä Monitor Green Environment
      id: monitor_green
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        SUCCESS_THRESHOLD="${{ github.event.inputs.success_threshold }}"
        
        echo "üìä Monitoring GREEN environment for 3 minutes..."
        
        ROLLBACK_NEEDED=false
        
        for i in {1..6}; do
          echo "üîç Monitoring check $i/6..."
          
          # Simulate production traffic monitoring
          ERROR_RATE=$(echo "scale=3; $RANDOM % 500 / 10000" | bc -l)
          SUCCESS_RATE=$(echo "scale=3; 1 - $ERROR_RATE" | bc -l)
          
          echo "üìà GREEN Environment Metrics:"
          echo "  Success Rate: $SUCCESS_RATE"
          echo "  Error Rate: $ERROR_RATE"
          
          if (( $(echo "$SUCCESS_RATE < $SUCCESS_THRESHOLD" | bc -l) )); then
            echo "‚ùå Success rate below threshold"
            ROLLBACK_NEEDED=true
            break
          fi
          
          echo "‚úÖ GREEN environment performing well"
          sleep 30
        done
        
        echo "rollback_needed=$ROLLBACK_NEEDED" >> $GITHUB_OUTPUT
        
    - name: üîô Rollback to Blue
      if: steps.monitor_green.outputs.rollback_needed == 'true' && github.event.inputs.auto_rollback == 'true'
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        
        echo "üö® Rolling back to BLUE environment"
        
        # Switch service back to blue (original)
        kubectl patch service $SERVICE -n ${{ env.NAMESPACE }} --type='merge' -p="
        {
          \"spec\": {
            \"selector\": {
              \"app\": \"$SERVICE\"
            }
          }
        }"
        
        # Remove blue-green VirtualService
        kubectl delete virtualservice ${SERVICE}-bluegreen-vs -n ${{ env.NAMESPACE }} --ignore-not-found=true
        
        # Clean up green resources
        kubectl delete deployment ${SERVICE}-green -n ${{ env.NAMESPACE }}
        kubectl delete service ${SERVICE}-green -n ${{ env.NAMESPACE }}
        
        echo "‚úÖ Rollback to BLUE completed"
        exit 1
        
    - name: üßπ Cleanup Blue Environment
      if: steps.monitor_green.outputs.rollback_needed == 'false'
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        
        echo "üßπ Cleaning up BLUE environment and promoting GREEN"
        
        # Delete old blue deployment
        kubectl delete deployment $SERVICE -n ${{ env.NAMESPACE }}
        
        # Rename green deployment to primary
        kubectl get deployment ${SERVICE}-green -n ${{ env.NAMESPACE }} -o yaml | \
        sed "s/name: ${SERVICE}-green/name: $SERVICE/" | \
        sed "s/app: ${SERVICE}-green/app: $SERVICE/" | \
        sed "s/version: green/version: v1/" | \
        kubectl apply -f -
        
        # Delete green deployment
        kubectl delete deployment ${SERVICE}-green -n ${{ env.NAMESPACE }}
        kubectl delete service ${SERVICE}-green -n ${{ env.NAMESPACE }}
        
        # Remove VirtualService
        kubectl delete virtualservice ${SERVICE}-bluegreen-vs -n ${{ env.NAMESPACE }} --ignore-not-found=true
        
        echo "‚úÖ Blue-Green deployment completed successfully"

  ab-testing:
    if: github.event.inputs.strategy == 'ab-testing'
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: üîÑ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üîê Azure Login via OIDC
      uses: azure/login@v1
      with:
        client-id: ${{ secrets.AZURE_CLIENT_ID }}
        tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        
    - name: ‚öôÔ∏è Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
        
    - name: üîó Get AKS Credentials
      run: |
        az aks get-credentials \
          --resource-group ${{ env.RESOURCE_GROUP }} \
          --name ${{ env.CLUSTER_NAME }} \
          --overwrite-existing
          
    - name: üÖ∞Ô∏èüÖ±Ô∏è Deploy A/B Testing Setup
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        TRAFFIC_PERCENT="${{ github.event.inputs.traffic_percentage }}"
        
        echo "üÖ∞Ô∏èüÖ±Ô∏è Setting up A/B testing for $SERVICE"
        
        # Deploy version B (new version)
        kubectl get deployment $SERVICE -n ${{ env.NAMESPACE }} -o yaml | \
        sed "s/name: $SERVICE/name: ${SERVICE}-version-b/" | \
        sed "s/app: $SERVICE/app: ${SERVICE}-version-b/" | \
        sed "s/version: v1/version: version-b/" | \
        sed "s/deployment-version.*/deployment-version: $NEW_VERSION/" | \
        kubectl apply -f -
        
        # Create service for version B
        kubectl get service $SERVICE -n ${{ env.NAMESPACE }} -o yaml | \
        sed "s/name: $SERVICE/name: ${SERVICE}-version-b/" | \
        sed "s/app: $SERVICE/app: ${SERVICE}-version-b/" | \
        kubectl apply -f -
        
        # Wait for version B to be ready
        kubectl wait --for=condition=available deployment/${SERVICE}-version-b -n ${{ env.NAMESPACE }} --timeout=300s
        
        # Create DestinationRule with A/B subsets
        cat << EOF | kubectl apply -f -
        apiVersion: networking.istio.io/v1beta1
        kind: DestinationRule
        metadata:
          name: ${SERVICE}-ab-dr
          namespace: ${{ env.NAMESPACE }}
        spec:
          host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
          subsets:
          - name: version-a
            labels:
              version: v1
          - name: version-b
            labels:
              version: version-b
        EOF
        
        # Create VirtualService with A/B routing based on user segments
        STABLE_PERCENT=$((100 - TRAFFIC_PERCENT))
        cat << EOF | kubectl apply -f -
        apiVersion: networking.istio.io/v1beta1
        kind: VirtualService
        metadata:
          name: ${SERVICE}-ab-vs
          namespace: ${{ env.NAMESPACE }}
        spec:
          hosts:
          - ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
          http:
          # Route beta users to version B
          - match:
            - headers:
                user-type:
                  exact: "beta"
            route:
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: version-b
              weight: 100
          # Route premium users to version B (higher percentage)
          - match:
            - headers:
                user-tier:
                  exact: "premium"
            route:
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: version-a
              weight: 50
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: version-b
              weight: 50
          # Default routing based on percentage
          - route:
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: version-a
              weight: $STABLE_PERCENT
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                subset: version-b
              weight: $TRAFFIC_PERCENT
        EOF
        
        echo "‚úÖ A/B testing setup completed"
        
    - name: üìä Collect A/B Testing Metrics
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        
        echo "üìä Collecting A/B testing metrics for 5 minutes..."
        
        for i in {1..10}; do
          echo "üìà A/B Metrics Collection $i/10..."
          
          # Simulate A/B testing metrics
          VERSION_A_CONVERSION=$(echo "scale=3; 0.150 + ($RANDOM % 50) / 1000" | bc -l)
          VERSION_B_CONVERSION=$(echo "scale=3; 0.180 + ($RANDOM % 40) / 1000" | bc -l)
          VERSION_A_LATENCY=$(echo "150 + $RANDOM % 50" | bc)
          VERSION_B_LATENCY=$(echo "140 + $RANDOM % 60" | bc)
          
          echo "üÖ∞Ô∏è Version A Metrics:"
          echo "  Conversion Rate: $VERSION_A_CONVERSION"
          echo "  Latency P95: ${VERSION_A_LATENCY}ms"
          
          echo "üÖ±Ô∏è Version B Metrics:"
          echo "  Conversion Rate: $VERSION_B_CONVERSION"
          echo "  Latency P95: ${VERSION_B_LATENCY}ms"
          
          # Calculate improvement
          IMPROVEMENT=$(echo "scale=2; ($VERSION_B_CONVERSION - $VERSION_A_CONVERSION) / $VERSION_A_CONVERSION * 100" | bc -l)
          echo "üìà Conversion Improvement: ${IMPROVEMENT}%"
          
          sleep 30
        done
        
        echo "‚úÖ A/B testing metrics collection completed"
        
    - name: üèÜ Determine Winner and Promote
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        
        # Simulate statistical analysis (in real scenario, use proper A/B testing tools)
        WINNER=$([ $((RANDOM % 2)) -eq 0 ] && echo "version-a" || echo "version-b")
        
        echo "üèÜ A/B Testing Winner: $WINNER"
        
        if [ "$WINNER" = "version-b" ]; then
          echo "üéâ Version B wins! Promoting to 100%"
          
          # Route 100% traffic to version B
          cat << EOF | kubectl apply -f -
          apiVersion: networking.istio.io/v1beta1
          kind: VirtualService
          metadata:
            name: ${SERVICE}-ab-vs
            namespace: ${{ env.NAMESPACE }}
          spec:
            hosts:
            - ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
            http:
            - route:
              - destination:
                  host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
                  subset: version-b
                weight: 100
          EOF
          
          # Replace version A with version B
          kubectl delete deployment $SERVICE -n ${{ env.NAMESPACE }}
          kubectl get deployment ${SERVICE}-version-b -n ${{ env.NAMESPACE }} -o yaml | \
          sed "s/name: ${SERVICE}-version-b/name: $SERVICE/" | \
          sed "s/app: ${SERVICE}-version-b/app: $SERVICE/" | \
          sed "s/version: version-b/version: v1/" | \
          kubectl apply -f -
          
          kubectl delete deployment ${SERVICE}-version-b -n ${{ env.NAMESPACE }}
          kubectl delete service ${SERVICE}-version-b -n ${{ env.NAMESPACE }}
          
        else
          echo "üèÜ Version A wins! Keeping current version"
          
          # Clean up version B
          kubectl delete deployment ${SERVICE}-version-b -n ${{ env.NAMESPACE }}
          kubectl delete service ${SERVICE}-version-b -n ${{ env.NAMESPACE }}
        fi
        
        # Clean up A/B testing resources
        kubectl delete virtualservice ${SERVICE}-ab-vs -n ${{ env.NAMESPACE }}
        kubectl delete destinationrule ${SERVICE}-ab-dr -n ${{ env.NAMESPACE }}
        
        echo "‚úÖ A/B testing completed and winner promoted"

  shadow-traffic:
    if: github.event.inputs.strategy == 'shadow-traffic'
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: üîÑ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üîê Azure Login via OIDC
      uses: azure/login@v1
      with:
        client-id: ${{ secrets.AZURE_CLIENT_ID }}
        tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        
    - name: ‚öôÔ∏è Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
        
    - name: üîó Get AKS Credentials
      run: |
        az aks get-credentials \
          --resource-group ${{ env.RESOURCE_GROUP }} \
          --name ${{ env.CLUSTER_NAME }} \
          --overwrite-existing
          
    - name: üë• Deploy Shadow Service
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        
        echo "üë• Deploying shadow service for $SERVICE version $NEW_VERSION"
        
        # Deploy shadow version
        kubectl get deployment $SERVICE -n ${{ env.NAMESPACE }} -o yaml | \
        sed "s/name: $SERVICE/name: ${SERVICE}-shadow/" | \
        sed "s/app: $SERVICE/app: ${SERVICE}-shadow/" | \
        sed "s/version: v1/version: shadow/" | \
        sed "s/deployment-version.*/deployment-version: $NEW_VERSION/" | \
        kubectl apply -f -
        
        # Create shadow service
        kubectl get service $SERVICE -n ${{ env.NAMESPACE }} -o yaml | \
        sed "s/name: $SERVICE/name: ${SERVICE}-shadow/" | \
        sed "s/app: $SERVICE/app: ${SERVICE}-shadow/" | \
        kubectl apply -f -
        
        # Wait for shadow deployment
        kubectl wait --for=condition=available deployment/${SERVICE}-shadow -n ${{ env.NAMESPACE }} --timeout=300s
        
        # Create VirtualService with traffic mirroring
        MIRROR_PERCENT="${{ github.event.inputs.traffic_percentage }}"
        cat << EOF | kubectl apply -f -
        apiVersion: networking.istio.io/v1beta1
        kind: VirtualService
        metadata:
          name: ${SERVICE}-shadow-vs
          namespace: ${{ env.NAMESPACE }}
        spec:
          hosts:
          - ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
          http:
          - route:
            - destination:
                host: ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
              weight: 100
            mirror:
              host: ${SERVICE}-shadow.${{ env.NAMESPACE }}.svc.cluster.local
            mirrorPercentage:
              value: ${MIRROR_PERCENT}
        EOF
        
        echo "‚úÖ Shadow traffic deployment completed with ${MIRROR_PERCENT}% mirroring"
        
    - name: üìä Analyze Shadow Traffic
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        
        echo "üìä Analyzing shadow traffic for 5 minutes..."
        
        for i in {1..10}; do
          echo "üîç Shadow Analysis $i/10..."
          
          # Simulate shadow traffic analysis
          PRODUCTION_LATENCY=$(echo "150 + $RANDOM % 50" | bc)
          SHADOW_LATENCY=$(echo "140 + $RANDOM % 60" | bc)
          PRODUCTION_ERRORS=$(echo "$RANDOM % 5" | bc)
          SHADOW_ERRORS=$(echo "$RANDOM % 8" | bc)
          
          echo "üè≠ Production Service:"
          echo "  Latency P95: ${PRODUCTION_LATENCY}ms"
          echo "  Error Count: $PRODUCTION_ERRORS"
          
          echo "üë• Shadow Service:"
          echo "  Latency P95: ${SHADOW_LATENCY}ms"
          echo "  Error Count: $SHADOW_ERRORS"
          
          # Compare performance
          if [ $SHADOW_LATENCY -lt $PRODUCTION_LATENCY ] && [ $SHADOW_ERRORS -le $PRODUCTION_ERRORS ]; then
            echo "‚úÖ Shadow service performing better or equal"
          else
            echo "‚ö†Ô∏è Shadow service showing degraded performance"
          fi
          
          sleep 30
        done
        
        echo "‚úÖ Shadow traffic analysis completed"
        
    - name: üéØ Promote or Rollback Shadow
      run: |
        SERVICE="${{ github.event.inputs.service }}"
        NEW_VERSION="${{ github.event.inputs.new_version }}"
        
        # Simulate decision based on shadow analysis
        PROMOTE=$([ $((RANDOM % 3)) -ne 0 ] && echo "true" || echo "false")
        
        if [ "$PROMOTE" = "true" ]; then
          echo "üéâ Shadow service passed analysis! Promoting to production"
          
          # Remove mirroring and switch to shadow
          cat << EOF | kubectl apply -f -
          apiVersion: networking.istio.io/v1beta1
          kind: VirtualService
          metadata:
            name: ${SERVICE}-shadow-vs
            namespace: ${{ env.NAMESPACE }}
          spec:
            hosts:
            - ${SERVICE}.${{ env.NAMESPACE }}.svc.cluster.local
            http:
            - route:
              - destination:
                  host: ${SERVICE}-shadow.${{ env.NAMESPACE }}.svc.cluster.local
                weight: 100
          EOF
          
          # Replace production with shadow
          kubectl delete deployment $SERVICE -n ${{ env.NAMESPACE }}
          kubectl get deployment ${SERVICE}-shadow -n ${{ env.NAMESPACE }} -o yaml | \
          sed "s/name: ${SERVICE}-shadow/name: $SERVICE/" | \
          sed "s/app: ${SERVICE}-shadow/app: $SERVICE/" | \
          sed "s/version: shadow/version: v1/" | \
          kubectl apply -f -
          
          kubectl delete deployment ${SERVICE}-shadow -n ${{ env.NAMESPACE }}
          kubectl delete service ${SERVICE}-shadow -n ${{ env.NAMESPACE }}
          
          echo "‚úÖ Shadow service promoted to production"
        else
          echo "‚ùå Shadow service failed analysis. Keeping production version"
          
          # Clean up shadow resources
          kubectl delete deployment ${SERVICE}-shadow -n ${{ env.NAMESPACE }}
          kubectl delete service ${SERVICE}-shadow -n ${{ env.NAMESPACE }}
        fi
        
        # Clean up VirtualService
        kubectl delete virtualservice ${SERVICE}-shadow-vs -n ${{ env.NAMESPACE }}
        
        echo "‚úÖ Shadow traffic testing completed"
