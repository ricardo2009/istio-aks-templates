# Load Testing Environment - 600k RPS

Este diretÃ³rio contÃ©m a infraestrutura e ferramentas para testes de carga de alta performance, projetados para atingir **600.000 requisiÃ§Ãµes por segundo (600k RPS)** na plataforma e-commerce.

## ğŸ¯ Objetivos de Performance

### Metas Principais
- **Throughput**: 600.000 RPS sustentados
- **LatÃªncia P95**: < 100ms
- **LatÃªncia P99**: < 200ms
- **Taxa de Erro**: < 0.01%
- **Disponibilidade**: 99.99%

### CenÃ¡rios de Teste
1. **Baseline Test**: ValidaÃ§Ã£o de funcionalidade bÃ¡sica
2. **Load Test**: Carga normal esperada (100k RPS)
3. **Stress Test**: Carga mÃ¡xima suportada (600k RPS)
4. **Spike Test**: Picos de trÃ¡fego (800k RPS por 5 minutos)
5. **Endurance Test**: Teste de resistÃªncia (24 horas a 300k RPS)

## ğŸ—ï¸ Arquitetura de Load Testing

### Componentes Principais

```
load-testing/
â”œâ”€â”€ infrastructure/          # Terraform para cluster de load testing
â”œâ”€â”€ tools/                  # Ferramentas de teste (K6, Artillery, NBomber)
â”œâ”€â”€ scenarios/              # CenÃ¡rios de teste especÃ­ficos
â”œâ”€â”€ data/                   # Dados de teste e fixtures
â”œâ”€â”€ scripts/                # Scripts de automaÃ§Ã£o
â”œâ”€â”€ monitoring/             # Dashboards e alertas especÃ­ficos
â”œâ”€â”€ results/                # Resultados e relatÃ³rios
â””â”€â”€ ci-cd/                  # Pipelines de teste automatizado
```

### Cluster de Load Testing
- **Nodes**: 20x Standard_D16s_v3 (16 vCPUs, 64GB RAM cada)
- **Total**: 320 vCPUs, 1.28TB RAM
- **Network**: Accelerated Networking habilitado
- **Storage**: Premium SSD para logs e resultados

### Ferramentas de Teste
1. **K6**: Testes de carga JavaScript/TypeScript
2. **Artillery**: Testes de carga Node.js
3. **NBomber**: Testes de carga .NET
4. **Vegeta**: Testes de carga Go
5. **Custom Tools**: Ferramentas especÃ­ficas em Python/Go

## ğŸš€ EstratÃ©gia de Escalonamento

### DistribuiÃ§Ã£o de Carga
- **Frontend**: 150k RPS (25%)
- **API Gateway**: 600k RPS (100%)
- **Product Service**: 300k RPS (50%)
- **User Service**: 120k RPS (20%)
- **Order Service**: 60k RPS (10%)
- **Payment Service**: 30k RPS (5%)

### PadrÃµes de TrÃ¡fego
- **Read Heavy**: 80% GET, 20% POST/PUT/DELETE
- **Cache Hit Rate**: 85% para produtos, 60% para usuÃ¡rios
- **Geographic Distribution**: 40% US, 30% EU, 20% APAC, 10% Others

## ğŸ“Š Monitoramento e MÃ©tricas

### MÃ©tricas Coletadas
- **Application Metrics**: LatÃªncia, throughput, taxa de erro
- **Infrastructure Metrics**: CPU, memÃ³ria, rede, disco
- **Istio Metrics**: Service mesh performance
- **Database Metrics**: CosmosDB RU/s, latÃªncia, throttling
- **Cache Metrics**: Redis hit rate, latÃªncia, memÃ³ria

### Dashboards
- **Real-time Performance**: MÃ©tricas em tempo real
- **Historical Analysis**: AnÃ¡lise de tendÃªncias
- **Error Analysis**: AnÃ¡lise detalhada de erros
- **Resource Utilization**: UtilizaÃ§Ã£o de recursos

## ğŸ”§ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos
1. Cluster AKS de load testing provisionado
2. Ferramentas de teste instaladas
3. Dados de teste preparados
4. Monitoramento configurado

### ExecuÃ§Ã£o RÃ¡pida
```bash
# Provisionar infraestrutura
cd infrastructure
terraform apply

# Executar teste bÃ¡sico
cd ../scripts
./run-baseline-test.sh

# Executar teste de 600k RPS
./run-stress-test.sh --target-rps=600000 --duration=30m

# Gerar relatÃ³rio
./generate-report.sh --test-id=stress-600k
```

### ExecuÃ§Ã£o AvanÃ§ada
```bash
# Teste customizado
./run-custom-test.sh \
  --scenario=ecommerce-peak \
  --target-rps=600000 \
  --duration=1h \
  --ramp-up=10m \
  --ramp-down=5m \
  --users=50000 \
  --regions=us-east,eu-west,asia-southeast

# Teste de endurance
./run-endurance-test.sh \
  --target-rps=300000 \
  --duration=24h \
  --check-interval=5m
```

## ğŸ“ˆ OtimizaÃ§Ãµes Implementadas

### AplicaÃ§Ã£o
- **Connection Pooling**: Pools otimizados para CosmosDB e Redis
- **Caching Strategy**: Multi-layer caching (L1: In-memory, L2: Redis, L3: CDN)
- **Async Processing**: Processamento assÃ­ncrono para operaÃ§Ãµes pesadas
- **Circuit Breakers**: ProteÃ§Ã£o contra cascading failures

### Infraestrutura
- **Node Optimization**: Nodes otimizados para alta performance
- **Network Optimization**: Accelerated networking e proximity placement
- **Storage Optimization**: Premium SSD com high IOPS
- **Kubernetes Optimization**: ConfiguraÃ§Ãµes otimizadas do kubelet

### Istio Service Mesh
- **Sidecar Optimization**: ConfiguraÃ§Ãµes otimizadas do Envoy
- **Traffic Management**: Load balancing e circuit breaking
- **Security**: mTLS otimizado para performance
- **Observability**: Telemetria otimizada

## ğŸ›ï¸ ConfiguraÃ§Ãµes de Performance

### NGINX Ingress
- **Worker Processes**: Auto (baseado em CPU cores)
- **Worker Connections**: 16384 por worker
- **Keepalive**: 10000 requests por connection
- **Buffer Sizes**: Otimizados para alta throughput

### KEDA Autoscaling
- **Scaling Triggers**: MÃºltiplas mÃ©tricas (RPS, CPU, Memory, Queue Length)
- **Scaling Speed**: Agressivo para scale-up, conservador para scale-down
- **Min/Max Replicas**: Configurado por serviÃ§o baseado em capacity planning

### CosmosDB
- **Provisioned Throughput**: 100,000 RU/s por container
- **Consistency Level**: Session (balance entre performance e consistÃªncia)
- **Indexing Policy**: Otimizado para queries especÃ­ficas
- **Partitioning**: EstratÃ©gia otimizada por workload

## ğŸ” AnÃ¡lise de Resultados

### RelatÃ³rios Gerados
1. **Performance Summary**: Resumo executivo dos resultados
2. **Detailed Metrics**: MÃ©tricas detalhadas por componente
3. **Error Analysis**: AnÃ¡lise detalhada de erros e falhas
4. **Resource Utilization**: UtilizaÃ§Ã£o de recursos durante o teste
5. **Recommendations**: RecomendaÃ§Ãµes de otimizaÃ§Ã£o

### CritÃ©rios de Sucesso
- âœ… **600k RPS sustentados** por pelo menos 30 minutos
- âœ… **P95 < 100ms** durante todo o teste
- âœ… **Taxa de erro < 0.01%** 
- âœ… **Zero downtime** durante o teste
- âœ… **Auto-scaling responsivo** (< 30s para scale-up)

## ğŸš¨ Troubleshooting

### Problemas Comuns
1. **High Latency**: Verificar CPU/Memory, network, database
2. **High Error Rate**: Verificar logs, circuit breakers, timeouts
3. **Scaling Issues**: Verificar KEDA metrics, resource limits
4. **Network Bottlenecks**: Verificar bandwidth, connections

### Ferramentas de Debug
- **kubectl**: Verificar status dos pods e recursos
- **istioctl**: Analisar configuraÃ§Ã£o do service mesh
- **Grafana**: Visualizar mÃ©tricas em tempo real
- **Jaeger**: Analisar traces distribuÃ­dos
- **Azure Monitor**: Monitorar recursos Azure

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Guia de ConfiguraÃ§Ã£o](./docs/configuration-guide.md)
- [CenÃ¡rios de Teste](./docs/test-scenarios.md)
- [Troubleshooting Guide](./docs/troubleshooting.md)
- [Performance Tuning](./docs/performance-tuning.md)
- [Best Practices](./docs/best-practices.md)
